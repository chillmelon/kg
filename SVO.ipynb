{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a900a03d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: py2neo in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (2021.2.3)\n",
      "Requirement already satisfied: pansi>=2020.7.3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (2020.7.3)\n",
      "Requirement already satisfied: packaging in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (21.3)\n",
      "Requirement already satisfied: monotonic in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (1.6)\n",
      "Requirement already satisfied: pygments>=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (2.11.2)\n",
      "Requirement already satisfied: certifi in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (2022.9.24)\n",
      "Requirement already satisfied: six>=1.15.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (1.16.0)\n",
      "Requirement already satisfied: urllib3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (1.26.12)\n",
      "Requirement already satisfied: interchange~=2021.0.4 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from py2neo) (2021.0.4)\n",
      "Requirement already satisfied: pytz in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from interchange~=2021.0.4->py2neo) (2022.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from packaging->py2neo) (3.0.9)\n",
      "Requirement already satisfied: wikipedia in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (1.4.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from wikipedia) (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from wikipedia) (4.11.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from beautifulsoup4->wikipedia) (2.3.2.post1)\n",
      "Requirement already satisfied: spacy==3.0.3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (3.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (2.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (21.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (0.10.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (1.7.4)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (0.3.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (1.0.9)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (3.1.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (1.21.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (4.11.3)\n",
      "Requirement already satisfied: pathy in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (0.6.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (4.64.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (3.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (2.0.7)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (2.4.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (0.7.9)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (65.5.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (8.0.17)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (3.0.8)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy==3.0.3) (4.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.1->spacy==3.0.3) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from packaging>=20.0->spacy==3.0.3) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.3) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.3) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.3) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy==3.0.3) (1.26.12)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy==3.0.3) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from jinja2->spacy==3.0.3) (2.1.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from pathy->spacy==3.0.3) (5.2.1)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-macosx_10_13_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.14.6 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from scikit-learn) (1.21.5)\n",
      "Collecting joblib>=0.11\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy>=1.1.0\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-macosx_10_9_x86_64.whl (33.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.0/33.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.0.2 scipy-1.7.3 threadpoolctl-3.1.0\n",
      "Requirement already satisfied: pandas in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from pandas) (1.21.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install py2neo\n",
    "!pip install wikipedia\n",
    "!pip install spacy==3.0.3\n",
    "!pip install scikit-learn\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01e48e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import urllib\n",
    "from pprint import pprint\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from py2neo import Node, Graph, Relationship, NodeMatcher\n",
    "from py2neo.bulk import merge_nodes\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import wikipedia\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Doc, Span, Token\n",
    "\n",
    "print(spacy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c74c47a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.0.0/en_core_web_md-3.0.0-py3-none-any.whl (47.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0mm\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from en-core-web-md==3.0.0) (3.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.8)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.21.5)\n",
      "Requirement already satisfied: pathy in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.6.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (8.0.17)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.7.9)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.10.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.28.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.64.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.11.3)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.4.5)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (4.1.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from catalogue<2.1.0,>=2.0.1->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.8.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (3.4)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (2.1.1)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from pathy->spacy<3.1.0,>=3.0.0->en-core-web-md==3.0.0) (5.2.1)\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.0.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "477c7814",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer']\n",
      "['tok2vec', 'tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer', 'merge_noun_chunks']\n"
     ]
    }
   ],
   "source": [
    "SUBJECTS = [\"nsubj\", \"nsubjpass\", \"csubj\", \"csubjpass\", \"agent\", \"expl\"]\n",
    "VERBS = ['ROOT', 'advcl']\n",
    "OBJECTS = [\"dobj\", \"dative\", \"attr\", \"oprd\", 'pobj']\n",
    "ENTITY_LABELS = ['PERSON', 'NORP', 'GPE', 'ORG', 'FAC', 'LOC', 'PRODUCT', 'EVENT', 'WORK_OF_ART']\n",
    "\n",
    "\n",
    "non_nc = spacy.load('en_core_web_md')\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe('merge_noun_chunks')\n",
    "\n",
    "print(non_nc.pipe_names)\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69b60fc",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e0a79e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_special_characters(text):\n",
    "    \n",
    "    regex = re.compile(r'[\\n\\r\\t]')\n",
    "    clean_text = regex.sub(\" \", text)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def remove_stop_words_and_punct(text, print_text=False):\n",
    "    \n",
    "    result_ls = []\n",
    "    rsw_doc = non_nc(text)\n",
    "    \n",
    "    for token in rsw_doc:\n",
    "        if print_text:\n",
    "            print(token, token.is_stop)\n",
    "            print('--------------')\n",
    "        if not token.is_stop and not token.is_punct:\n",
    "            result_ls.append(str(token))\n",
    "    \n",
    "    result_str = ' '.join(result_ls)\n",
    "\n",
    "    return result_str\n",
    "\n",
    "\n",
    "def create_svo_lists(doc, print_lists):\n",
    "    \n",
    "    subject_ls = []\n",
    "    verb_ls = []\n",
    "    object_ls = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.dep_ in SUBJECTS:\n",
    "            subject_ls.append((token.lower_, token.idx))\n",
    "        elif token.dep_ in VERBS:\n",
    "            verb_ls.append((token.lemma_, token.idx))\n",
    "        elif token.dep_ in OBJECTS:\n",
    "            object_ls.append((token.lower_, token.idx))\n",
    "\n",
    "    if print_lists:\n",
    "        print('SUBJECTS: ', subject_ls)\n",
    "        print('VERBS: ', verb_ls)\n",
    "        print('OBJECTS: ', object_ls)\n",
    "    \n",
    "    return subject_ls, verb_ls, object_ls\n",
    "\n",
    "\n",
    "def remove_duplicates(tup, tup_posn):\n",
    "    \n",
    "    check_val = set()\n",
    "    result = []\n",
    "    \n",
    "    for i in tup:\n",
    "        if i[tup_posn] not in check_val:\n",
    "            result.append(i)\n",
    "            check_val.add(i[tup_posn])\n",
    "            \n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_dates(tup_ls):\n",
    "    \n",
    "    clean_tup_ls = []\n",
    "    for entry in tup_ls:\n",
    "        if not entry[2].isdigit():\n",
    "            clean_tup_ls.append(entry)\n",
    "    return clean_tup_ls\n",
    "\n",
    "\n",
    "def create_svo_triples(text, print_lists=False):\n",
    "    \n",
    "    clean_text = remove_special_characters(text)\n",
    "    doc = nlp(clean_text)\n",
    "    subject_ls, verb_ls, object_ls = create_svo_lists(doc, print_lists=print_lists)\n",
    "    \n",
    "    graph_tup_ls = []\n",
    "    dedup_tup_ls = []\n",
    "    clean_tup_ls = []\n",
    "    \n",
    "    for subj in subject_ls: \n",
    "        for obj in object_ls:\n",
    "            \n",
    "            dist_ls = []\n",
    "            \n",
    "            for v in verb_ls:\n",
    "                \n",
    "                # Assemble a list of distances between each object and each verb\n",
    "                dist_ls.append(abs(obj[1] - v[1]))\n",
    "                \n",
    "            # Get the index of the verb with the smallest distance to the object \n",
    "            # and return that verb\n",
    "            index_min = min(range(len(dist_ls)), key=dist_ls.__getitem__)\n",
    "            \n",
    "            # Remve stop words from subjects and object.  Note that we do this a bit\n",
    "            # later down in the process to allow for proper sentence recognition.\n",
    "\n",
    "            no_sw_subj = remove_stop_words_and_punct(subj[0])\n",
    "            no_sw_obj = remove_stop_words_and_punct(obj[0])\n",
    "            \n",
    "            # Add entries to the graph iff neither subject nor object is blank\n",
    "            if no_sw_subj and no_sw_obj:\n",
    "                tup = (no_sw_subj, verb_ls[index_min][0], no_sw_obj)\n",
    "                graph_tup_ls.append(tup)\n",
    "        \n",
    "        #clean_tup_ls = remove_dates(graph_tup_ls)\n",
    "    \n",
    "    dedup_tup_ls = remove_duplicates(graph_tup_ls, 2)\n",
    "    clean_tup_ls = remove_dates(dedup_tup_ls)\n",
    "    \n",
    "    return clean_tup_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b764e979",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0db2944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obj_properties(tup_ls):\n",
    "    \n",
    "    init_obj_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "\n",
    "        try:\n",
    "            text, node_label_ls, url = query_google(tup[2], api_key, limit=1)\n",
    "            new_tup = (tup[0], tup[1], tup[2], text[0], node_label_ls[0], url[0])\n",
    "        except:\n",
    "            new_tup = (tup[0], tup[1], tup[2], [], [], [])\n",
    "        \n",
    "        init_obj_tup_ls.append(new_tup)\n",
    "        \n",
    "    return init_obj_tup_ls\n",
    "\n",
    "\n",
    "def add_layer(tup_ls):\n",
    "\n",
    "    svo_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        \n",
    "        if tup[3]:\n",
    "            svo_tup = create_svo_triples(tup[3])\n",
    "            svo_tup_ls.extend(svo_tup)\n",
    "        else:\n",
    "            continue\n",
    "    \n",
    "    return get_obj_properties(svo_tup_ls)\n",
    "        \n",
    "\n",
    "def subj_equals_obj(tup_ls):\n",
    "    \n",
    "    new_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if tup[0] != tup[2]:\n",
    "            new_tup_ls.append((tup[0], tup[1], tup[2], tup[3], tup[4], tup[5]))\n",
    "            \n",
    "    return new_tup_ls\n",
    "\n",
    "\n",
    "def check_for_string_labels(tup_ls):\n",
    "    # This is for an edge case where the object does not get fully populated\n",
    "    # resulting in the node labels being assigned to string instead of list.\n",
    "    # This may not be strictly necessary and the lines using it are commnted out\n",
    "    # below.  Run this function if you come across this case.\n",
    "    \n",
    "    clean_tup_ls = []\n",
    "    \n",
    "    for el in tup_ls:\n",
    "        if isinstance(el[2], list):\n",
    "            clean_tup_ls.append(el)\n",
    "            \n",
    "    return clean_tup_ls\n",
    "\n",
    "\n",
    "def create_word_vectors(tup_ls):\n",
    "\n",
    "    new_tup_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if tup[3]:\n",
    "            doc = nlp(tup[3])\n",
    "            new_tup = (tup[0], tup[1], tup[2], tup[3], tup[4], tup[5], doc.vector)\n",
    "        else:\n",
    "            new_tup = (tup[0], tup[1], tup[2], tup[3], tup[4], tup[5], np.random.uniform(low=-1.0, high=1.0, size=(300,)))\n",
    "        new_tup_ls.append(new_tup)\n",
    "        \n",
    "    return new_tup_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64cbf88",
   "metadata": {},
   "source": [
    "## Create the node and edge lists to populate the graph with the below helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2174d8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedup(tup_ls):\n",
    "    \n",
    "    visited = set()\n",
    "    output_ls = []\n",
    "    \n",
    "    for tup in tup_ls:\n",
    "        if not tup[0] in visited:\n",
    "            visited.add(tup[0])\n",
    "            output_ls.append((tup[0], tup[1], tup[2], tup[3], tup[4]))\n",
    "            \n",
    "    return output_ls\n",
    "\n",
    "\n",
    "def convert_vec_to_ls(tup_ls):\n",
    "    \n",
    "    vec_to_ls_tup = []\n",
    "    \n",
    "    for el in tup_ls:\n",
    "        vec_ls = [float(v) for v in el[4]]\n",
    "        tup = (el[0], el[1], el[2], el[3], vec_ls)\n",
    "        vec_to_ls_tup.append(tup)\n",
    "        \n",
    "    return vec_to_ls_tup\n",
    "\n",
    "\n",
    "def add_nodes(tup_ls):   \n",
    "\n",
    "    keys = ['name', 'description', 'node_labels', 'url', 'word_vec']\n",
    "    merge_nodes(graph.auto(), tup_ls, ('Node', 'name'), keys=keys)\n",
    "    print('Number of nodes in graph: ', graph.nodes.match('Node').count())\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "113cd7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_edges(edge_ls):\n",
    "    \n",
    "    edge_dc = {} \n",
    "    \n",
    "    # Group tuple by verb\n",
    "    # Result: {verb1: [(sub1, v1, obj1), (sub2, v2, obj2), ...],\n",
    "    #          verb2: [(sub3, v3, obj3), (sub4, v4, obj4), ...]}\n",
    "    \n",
    "    for tup in edge_ls: \n",
    "        if tup[1] in edge_dc: \n",
    "            edge_dc[tup[1]].append((tup[0], tup[1], tup[2])) \n",
    "        else: \n",
    "            edge_dc[tup[1]] = [(tup[0], tup[1], tup[2])] \n",
    "    \n",
    "    for edge_labels, tup_ls in tqdm(edge_dc.items()):   # k=edge labels, v = list of tuples\n",
    "        \n",
    "        tx = graph.begin()\n",
    "        \n",
    "        for el in tup_ls:\n",
    "            source_node = nodes_matcher.match(name=el[0]).first()\n",
    "            target_node = nodes_matcher.match(name=el[2]).first()\n",
    "            if not source_node:\n",
    "                source_node = Node('Node', name=el[0])\n",
    "                tx.create(source_node)\n",
    "            if not target_node:\n",
    "                try:\n",
    "                    target_node = Node('Node', name=el[2], node_labels=el[4], url=el[5], word_vec=el[6])\n",
    "                    tx.create(target_node)\n",
    "                except:\n",
    "                    continue\n",
    "            try:\n",
    "                rel = Relationship(source_node, edge_labels, target_node)\n",
    "            except:\n",
    "                continue\n",
    "            tx.create(rel)\n",
    "        tx.commit()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d415de94",
   "metadata": {},
   "source": [
    "## Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e91ed217",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('./data/test.txt', 'r')\n",
    "text = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4d1827",
   "metadata": {},
   "source": [
    "## Read PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d814b6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Using cached PyPDF2-2.11.1-py3-none-any.whl (220 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages (from PyPDF2) (4.1.1)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-2.11.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2\n",
    "\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c86ec486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "reader = PdfReader(\"./data/test.pdf\")\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text += page.extract_text() + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "62f49d8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reader.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8a6150b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = reader.pages[20].extract_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa772f5",
   "metadata": {},
   "source": [
    "## Start Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f0ae5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "initial_tup_ls = create_svo_triples(text, print_lists=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8945919d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_tup_ls[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f3c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "init_obj_tup_ls = get_obj_properties(initial_tup_ls)\n",
    "new_layer_ls = add_layer(init_obj_tup_ls)\n",
    "starter_edge_ls = init_obj_tup_ls + new_layer_ls\n",
    "edge_ls = subj_equals_obj(starter_edge_ls)\n",
    "#clean_edge_ls = check_for_string_labels(edge_ls)\n",
    "#clean_edge_ls[0:3]\n",
    "clean_edge_ls = edge_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_word_vec_ls = create_word_vectors(edge_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f1ed9b",
   "metadata": {},
   "source": [
    "## Creating some lists of tuples representing the node and edge lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a127f32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_node_tup_ls = [(edge_ls[0][0], '', ['Subject'], '', np.random.uniform(low=-1.0, high=1.0, size=(300,)))]\n",
    "obj_node_tup_ls = [(tup[2], tup[3], tup[4], tup[5], tup[6]) for tup in edges_word_vec_ls]\n",
    "full_node_tup_ls = orig_node_tup_ls + obj_node_tup_ls\n",
    "dedup_node_tup_ls = dedup(full_node_tup_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77328b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(full_node_tup_ls), len(dedup_node_tup_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbdd691",
   "metadata": {},
   "source": [
    "## Create the node list that will be used to populate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f99146f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_tup_ls = convert_vec_to_ls(dedup_node_tup_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebb83df",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Graph(\"bolt://localhost:7999\", name=\"neo4j\", password=\"secret\")\n",
    "nodes_matcher = NodeMatcher(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "add_nodes(node_tup_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8e9143",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "add_edges(edges_word_vec_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca648337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a23313d8",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "ce5cb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec_similarity(node1, node2, node_ls):\n",
    "    \n",
    "    node1_vec = [tup[4] for tup in node_ls if tup[0] == node1]\n",
    "    node2_vec = [tup[4] for tup in node_ls if tup[0] == node2]\n",
    "    \n",
    "    return cosine_similarity(node1_vec, node2_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b147399b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n1/2zm5xp6j61vf81xl29r2r_f40000gn/T/ipykernel_34668/1780345665.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_word_vec_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'company'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'standard'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdedup_node_tup_ls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n1/2zm5xp6j61vf81xl29r2r_f40000gn/T/ipykernel_34668/4060914436.py\u001b[0m in \u001b[0;36mget_word_vec_similarity\u001b[0;34m(node1, node2, node_ls)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mnode2_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode_ls\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnode2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode1_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode2_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1249\u001b[0m     \u001b[0;31m# to avoid recursive import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_pairwise_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[0mX_normalized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    160\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         )\n\u001b[1;32m    164\u001b[0m         Y = check_array(\n",
      "\u001b[0;32m/usr/local/Caskroom/miniconda/base/envs/kg2/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "cs = get_word_vec_similarity('company', 'standard', dedup_node_tup_ls)\n",
    "print(cs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
